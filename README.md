# ğŸ§¬ Genetic Algorithm Neural Network for MNIST

[![C++](https://img.shields.io/badge/C++-17-blue.svg?style=flat&logo=c%2B%2B)](https://isocpp.org/)
[![OpenMP](https://img.shields.io/badge/OpenMP-Parallel-green.svg)](https://www.openmp.org/)
[![Build Status](https://img.shields.io/badge/Build-Passing-brightgreen.svg)](https://github.com)

> ğŸš€ A high-performance implementation of Genetic Algorithm optimization for Neural Networks, specifically designed for MNIST digit classification with OpenMP parallelization.

## ğŸ“‹ Table of Contents

- [ğŸŒŸ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ”§ Prerequisites](#-prerequisites)
- [âš¡ Installation](#-installation)
- [ğŸ¯ Usage](#-usage)
- [ğŸ“Š Performance](#-performance)
- [ğŸ§ª Genetic Operations](#-genetic-operations)
- [ğŸ“ˆ Results](#-results)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

## ğŸŒŸ Features

âœ¨ **Key Highlights:**
- ğŸ§  **Neural Network**: 2-layer feedforward network (784â†’128â†’10)
- ğŸ§¬ **Genetic Algorithm**: Evolution-based weight optimization
- âš¡ **OpenMP Parallelization**: Multi-threaded performance boost
- ğŸ“Š **MNIST Dataset**: Handwritten digit recognition
- ğŸ¯ **Multiple Mutation Strategies**: Gaussian addition/subtraction with crossover
- ğŸ“ˆ **Real-time Performance Tracking**: Generation-by-generation accuracy monitoring

## ğŸ—ï¸ Architecture

```
Input Layer (784) â†’ Hidden Layer (128) â†’ Output Layer (10)
                  â†“
               Sigmoid        Softmax
```

## ğŸ”§ Prerequisites

Before you begin, ensure you have:

- ğŸ–¥ï¸ **C++ Compiler**: GCC 7.0+ or Clang 5.0+ with C++17 support
- ğŸ”„ **OpenMP**: For parallel processing capabilities
- ğŸ“ **MNIST Dataset**: CSV format (`mnist.csv`)

### ğŸ“¦ System Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| RAM | 4GB | 8GB+ |
| CPU Cores | 2 | 4+ |
| Storage | 100MB | 500MB |

## âš¡ Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/genetic-neural-network.git
cd genetic-neural-network
```

### 2ï¸âƒ£ Prepare MNIST Dataset
Download the MNIST dataset in CSV format and place it as `mnist.csv` in the project directory.

### 3ï¸âƒ£ Compile the Code

#### ğŸ”„ With OpenMP (Recommended)
```bash
g++ -std=c++17 -fopenmp -O3 -o genetic_nn_parallel genetic_nn_parallel.cpp
```

#### ğŸ“± Sequential Version
```bash
g++ -std=c++17 -O3 -o genetic_nn_sequential genetic_nn_sequential.cpp
```

## ğŸ¯ Usage

### ğŸš€ Run with Parallelization
```bash
./genetic_nn_parallel
```

### ğŸŒ Run Sequential Version
```bash
./genetic_nn_sequential
```

### âš™ï¸ Configuration

Modify these parameters in the source code:

```cpp
const int organisms = 40;      // Population size
int generations = 40;          // Number of generations
int hiddenSize = 128;          // Hidden layer neurons
```

## ğŸ“Š Performance

### ğŸƒâ€â™‚ï¸ Speed Comparison

| Version | Population | Generations | Avg. Time/Generation |
|---------|------------|-------------|---------------------|
| Sequential | 10 | 10 | ~15-20 seconds |
| Parallel (4 cores) | 40 | 40 | ~8-12 seconds |

### ğŸ“ˆ Typical Results
- ğŸ¯ **Initial Accuracy**: ~10-15%
- ğŸš€ **Final Accuracy**: ~60-80% (varies by run)
- â±ï¸ **Convergence**: Usually within 20-30 generations

## ğŸ§ª Genetic Operations

### ğŸ§¬ Selection Strategy
- **Elite Selection**: Top 2 performers always survive
- **Crossover**: Weight mixing between top 8 organisms
- **Tournament Selection**: Random selection from top performers

### ğŸ”„ Mutation Types

| Operation | Description | Probability |
|-----------|-------------|-------------|
| **Crossover** | Mix weights between two parents | 20% |
| **Add Gaussian** | Add random noise to weights | 20% |
| **Sub Gaussian** | Subtract noise + multiply | 20% |
| **Crossover + Add** | Crossover followed by addition | 20% |
| **Crossover + Sub** | Crossover followed by subtraction | 20% |

## ğŸ“ˆ Results

### ğŸ† Sample Output
```
####Details####
Total Organisms : 40
Generations : 40

MNIST dataset loaded successfully!
Number of samples: 60000

______Generation 0_____
Organism 0 Accuracy: 12.34
Organism 1 Accuracy: 15.67
...
Top Accuracy : 78.45

Time taken by generation : 8 seconds
```

### ğŸ“Š Performance Visualization
The algorithm typically shows:
- ğŸ“ˆ **Rapid Initial Growth**: 10% â†’ 40% in first 10 generations
- ğŸ¯ **Steady Improvement**: 40% â†’ 70% in next 20 generations  
- ğŸ”ï¸ **Plateau Phase**: Final 10 generations for fine-tuning


## ğŸ“ Code Structure

```
â”œâ”€â”€ genetic_nn_parallel.cpp    # OpenMP parallelized version
â”œâ”€â”€ genetic_nn_sequential.cpp  # Sequential version
â”œâ”€â”€ mnist.csv                  # MNIST dataset (not included)
â””â”€â”€ README.md                  # This file
```

## ğŸ” Key Classes and Functions

### ğŸ§  `SimpleANN` Class
- **Constructor**: Initialize network with random weights
- **`forwardPropagation()`**: Calculate network output
- **`calculateAccuracy()`**: Evaluate performance on dataset
- **`add_gaussian()`**: Add mutation noise
- **`sub_gaussian()`**: Subtract and multiply mutation

### ğŸ§¬ Genetic Functions
- **`compareByPerformance()`**: Sort organisms by fitness
- **Selection Logic**: Choose parents for next generation
- **Crossover Operations**: Mix genetic material

## ğŸ› Troubleshooting

### Common Issues:

**âŒ Compilation Error**: `fatal error: omp.h: No such file`
```bash
# Install OpenMP
sudo apt-get install libomp-dev  # Ubuntu/Debian
brew install libomp              # macOS
```

**âŒ Dataset Not Found**: `Error: Unable to open the CSV file`
- Ensure `mnist.csv` is in the project directory
- Check file permissions

**âŒ Poor Performance**: Accuracy stuck below 20%
- Try different random seeds
- Adjust mutation rates
- Increase population size or generations

## ğŸ“ Educational Value

This project demonstrates:
- ğŸ§¬ **Genetic Algorithms**: Population-based optimization
- ğŸ§  **Neural Networks**: Feedforward architecture
- âš¡ **Parallel Computing**: OpenMP implementation
- ğŸ“Š **Machine Learning**: Classification problem solving
- ğŸ”„ **Evolutionary Computing**: Bio-inspired algorithms


Made with â¤ï¸ by NiceGuy

</div>
